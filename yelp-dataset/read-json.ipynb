{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6facfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews...\n",
      "Found 698 reviews mentioning black sesame\n",
      "\n",
      "Sample reviews:\n",
      "                   business_id  \\\n",
      "19640   MFxRPt8-B2xTYmon3s84kg   \n",
      "58970   nFjk0xVI9fNiVN__5g-m8Q   \n",
      "224605  MFxRPt8-B2xTYmon3s84kg   \n",
      "225400  msHYY8zS_8D3_BJitdGdmA   \n",
      "228196  hmmiyt6KljD5G3a861qsKw   \n",
      "\n",
      "                                                     text                 date  \n",
      "19640   Cute place with friendly owner.  We sampled th...  2018-09-25 20:48:54  \n",
      "58970   We had Brunchuru at Ichicoro Ane in St. Peters...  2018-09-30 21:52:58  \n",
      "224605  Hands down, the best soft serve ice cream I've...  2018-11-11 04:41:17  \n",
      "225400  I have been to this location about three times...  2010-01-31 00:10:46  \n",
      "228196  K & S is great for specific things. It's not r...  2008-08-03 01:46:11  \n",
      "\n",
      "Involves 334 businesses\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load review data\n",
    "print(\"Loading reviews...\")\n",
    "reviews = []\n",
    "with open('yelp_academic_dataset_review.json', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        reviews.append(json.loads(line))\n",
    "\n",
    "df_reviews = pd.DataFrame(reviews)\n",
    "\n",
    "# 2. Search for \"black sesame\" mentions\n",
    "black_sesame_reviews = df_reviews[\n",
    "    df_reviews['text'].str.contains('black sesame', case=False, na=False)\n",
    "]\n",
    "\n",
    "print(f\"Found {len(black_sesame_reviews)} reviews mentioning black sesame\")\n",
    "\n",
    "# 3. View sample results\n",
    "print(\"\\nSample reviews:\")\n",
    "print(black_sesame_reviews[['business_id', 'text', 'date']].head())\n",
    "\n",
    "# 4. Get unique restaurant IDs\n",
    "business_ids = black_sesame_reviews['business_id'].unique()\n",
    "print(f\"\\nInvolves {len(business_ids)} businesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c298958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yearly trend:\n",
      "year\n",
      "2007      1\n",
      "2008      7\n",
      "2009      8\n",
      "2010     11\n",
      "2011     24\n",
      "2012     19\n",
      "2013     34\n",
      "2014     43\n",
      "2015     47\n",
      "2016     66\n",
      "2017    101\n",
      "2018    119\n",
      "2019    114\n",
      "2020     49\n",
      "2021     51\n",
      "2022      4\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/twx6v7jj4nq17ymrbt5c1klw0000gn/T/ipykernel_15738/288771188.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['year'] = pd.to_datetime(matches['date']).dt.year\n"
     ]
    }
   ],
   "source": [
    "# Search for multiple related terms\n",
    "keywords = [\n",
    "    'black sesame', \n",
    "    'black sesame latte', \n",
    "    'black sesame ice cream',\n",
    "    'black sesame mochi',\n",
    "    'kuro goma',  # Japanese\n",
    "    'heugimja'    # Korean\n",
    "]\n",
    "\n",
    "pattern = '|'.join(keywords)\n",
    "matches = df_reviews[\n",
    "    df_reviews['text'].str.contains(pattern, case=False, na=False)\n",
    "]\n",
    "\n",
    "# Analyze trends by year\n",
    "matches['year'] = pd.to_datetime(matches['date']).dt.year\n",
    "yearly_trend = matches.groupby('year').size()\n",
    "print(\"\\nYearly trend:\")\n",
    "print(yearly_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdec225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading business data...\n",
      "\n",
      "Top 10 cities:\n",
      "city\n",
      "Philadelphia     303\n",
      "Reno              68\n",
      "Santa Barbara     49\n",
      "Edmonton          39\n",
      "New Orleans       30\n",
      "Nashville         26\n",
      "Tampa             24\n",
      "Saint Louis       21\n",
      "Indianapolis      15\n",
      "Tucson            13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Results saved to black_sesame_restaurants.csv\n"
     ]
    }
   ],
   "source": [
    "# 1. Load business data\n",
    "print(\"Loading business data...\")\n",
    "businesses = []\n",
    "with open('yelp_academic_dataset_business.json', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        businesses.append(json.loads(line))\n",
    "\n",
    "df_business = pd.DataFrame(businesses)\n",
    "\n",
    "# 2. Merge reviews with business info\n",
    "result = black_sesame_reviews.merge(\n",
    "    df_business[['business_id', 'name', 'address', 'city', 'state', \n",
    "                 'latitude', 'longitude', 'categories']],\n",
    "    on='business_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. Top cities for black sesame mentions\n",
    "print(\"\\nTop 10 cities:\")\n",
    "print(result['city'].value_counts().head(10))\n",
    "\n",
    "# 4. Export results\n",
    "result.to_csv('black_sesame_restaurants.csv', index=False)\n",
    "print(\"\\nResults saved to black_sesame_restaurants.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc28917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black_sesame: 698 mentions\n",
      "matcha: 6068 mentions\n",
      "ube: 66201 mentions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/twx6v7jj4nq17ymrbt5c1klw0000gn/T/ipykernel_15738/1260658731.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['year'] = pd.to_datetime(matches['date']).dt.year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "black_sesame yearly trend:\n",
      "year\n",
      "2007      1\n",
      "2008      7\n",
      "2009      8\n",
      "2010     11\n",
      "2011     24\n",
      "2012     19\n",
      "2013     34\n",
      "2014     43\n",
      "2015     47\n",
      "2016     66\n",
      "2017    101\n",
      "2018    119\n",
      "2019    114\n",
      "2020     49\n",
      "2021     51\n",
      "2022      4\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/twx6v7jj4nq17ymrbt5c1klw0000gn/T/ipykernel_15738/1260658731.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['year'] = pd.to_datetime(matches['date']).dt.year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "matcha yearly trend:\n",
      "year\n",
      "2007       4\n",
      "2008       7\n",
      "2009      17\n",
      "2010      14\n",
      "2011      35\n",
      "2012      50\n",
      "2013      84\n",
      "2014     153\n",
      "2015     285\n",
      "2016     581\n",
      "2017     810\n",
      "2018    1199\n",
      "2019    1071\n",
      "2020     705\n",
      "2021     999\n",
      "2022      54\n",
      "dtype: int64\n",
      "\n",
      "ube yearly trend:\n",
      "year\n",
      "2005       3\n",
      "2006      20\n",
      "2007     129\n",
      "2008     570\n",
      "2009     772\n",
      "2010    1403\n",
      "2011    2156\n",
      "2012    2420\n",
      "2013    3070\n",
      "2014    4082\n",
      "2015    5326\n",
      "2016    6581\n",
      "2017    7993\n",
      "2018    9507\n",
      "2019    9050\n",
      "2020    6063\n",
      "2021    6674\n",
      "2022     382\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/twx6v7jj4nq17ymrbt5c1klw0000gn/T/ipykernel_15738/1260658731.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matches['year'] = pd.to_datetime(matches['date']).dt.year\n"
     ]
    }
   ],
   "source": [
    "# Compare black sesame vs matcha vs ube\n",
    "asian_flavors = {\n",
    "    'black_sesame': ['black sesame', 'kuro goma'],\n",
    "    'matcha': ['matcha', 'green tea latte'],\n",
    "    'ube': ['ube', 'purple yam', 'taro']\n",
    "}\n",
    "\n",
    "comparison = {}\n",
    "\n",
    "for flavor, keywords in asian_flavors.items():\n",
    "    pattern = '|'.join(keywords)\n",
    "    matches = df_reviews[\n",
    "        df_reviews['text'].str.contains(pattern, case=False, na=False)\n",
    "    ]\n",
    "    comparison[flavor] = len(matches)\n",
    "    print(f\"{flavor}: {len(matches)} mentions\")\n",
    "\n",
    "# Trend over time\n",
    "for flavor, keywords in asian_flavors.items():\n",
    "    pattern = '|'.join(keywords)\n",
    "    matches = df_reviews[\n",
    "        df_reviews['text'].str.contains(pattern, case=False, na=False)\n",
    "    ]\n",
    "    matches['year'] = pd.to_datetime(matches['date']).dt.year\n",
    "    trend = matches.groupby('year').size()\n",
    "    print(f\"\\n{flavor} yearly trend:\")\n",
    "    print(trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c452011a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14348 cafes/dessert shops\n",
      "Black sesame mentions in cafes: 339\n"
     ]
    }
   ],
   "source": [
    "# Focus on cafes, dessert shops, and ice cream parlors\n",
    "cafe_categories = [\n",
    "    'Coffee', 'Cafe', 'Dessert', 'Ice Cream', \n",
    "    'Bakeries', 'Bubble Tea', 'Gelato'\n",
    "]\n",
    "\n",
    "# Filter businesses\n",
    "category_pattern = '|'.join(cafe_categories)\n",
    "cafes = df_business[\n",
    "    df_business['categories'].str.contains(category_pattern, case=False, na=False)\n",
    "]\n",
    "\n",
    "print(f\"Found {len(cafes)} cafes/dessert shops\")\n",
    "\n",
    "# Find black sesame mentions in these cafes\n",
    "cafe_ids = set(cafes['business_id'])\n",
    "black_sesame_in_cafes = black_sesame_reviews[\n",
    "    black_sesame_reviews['business_id'].isin(cafe_ids)\n",
    "]\n",
    "\n",
    "print(f\"Black sesame mentions in cafes: {len(black_sesame_in_cafes)}\")\n",
    "\n",
    "# Merge with cafe details\n",
    "cafe_analysis = black_sesame_in_cafes.merge(\n",
    "    cafes[['business_id', 'name', 'city', 'state', 'latitude', 'longitude']],\n",
    "    on='business_id'\n",
    ")\n",
    "\n",
    "cafe_analysis.to_csv('black_sesame_cafes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb827a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "black sesame: 698 mentions\n",
      "matcha: 5864 mentions\n",
      "ube: 60161 mentions\n",
      "\n",
      "black sesame yearly trend:\n",
      "year\n",
      "2007      1\n",
      "2008      7\n",
      "2009      8\n",
      "2010     11\n",
      "2011     24\n",
      "2012     19\n",
      "2013     34\n",
      "2014     43\n",
      "2015     47\n",
      "2016     66\n",
      "2017    101\n",
      "2018    119\n",
      "2019    114\n",
      "2020     49\n",
      "2021     51\n",
      "2022      4\n",
      "dtype: int64\n",
      "\n",
      "matcha yearly trend:\n",
      "year\n",
      "2007       3\n",
      "2008       4\n",
      "2009      12\n",
      "2010      12\n",
      "2011      29\n",
      "2012      40\n",
      "2013      69\n",
      "2014     139\n",
      "2015     263\n",
      "2016     550\n",
      "2017     784\n",
      "2018    1171\n",
      "2019    1048\n",
      "2020     694\n",
      "2021     992\n",
      "2022      54\n",
      "dtype: int64\n",
      "\n",
      "ube yearly trend:\n",
      "year\n",
      "2005       2\n",
      "2006      17\n",
      "2007     111\n",
      "2008     516\n",
      "2009     669\n",
      "2010    1278\n",
      "2011    1958\n",
      "2012    2177\n",
      "2013    2763\n",
      "2014    3634\n",
      "2015    4824\n",
      "2016    6057\n",
      "2017    7380\n",
      "2018    8665\n",
      "2019    8246\n",
      "2020    5503\n",
      "2021    6025\n",
      "2022     336\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j5/twx6v7jj4nq17ymrbt5c1klw0000gn/T/ipykernel_15738/182456421.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['year'] = pd.to_datetime(data['date']).dt.year\n",
      "/var/folders/j5/twx6v7jj4nq17ymrbt5c1klw0000gn/T/ipykernel_15738/182456421.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['year'] = pd.to_datetime(data['date']).dt.year\n",
      "/var/folders/j5/twx6v7jj4nq17ymrbt5c1klw0000gn/T/ipykernel_15738/182456421.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['year'] = pd.to_datetime(data['date']).dt.year\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 cities:\n",
      "city\n",
      "Philadelphia     303\n",
      "Reno              68\n",
      "Santa Barbara     49\n",
      "Edmonton          39\n",
      "New Orleans       30\n",
      "Nashville         26\n",
      "Tampa             24\n",
      "Saint Louis       21\n",
      "Indianapolis      15\n",
      "Tucson            13\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Analysis complete! Results saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "def load_yelp_data():\n",
    "    \"\"\"Load all Yelp dataset files\"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    \n",
    "    # Load reviews\n",
    "    reviews = []\n",
    "    with open('yelp_academic_dataset_review.json', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            reviews.append(json.loads(line))\n",
    "    \n",
    "    # Load businesses\n",
    "    businesses = []\n",
    "    with open('yelp_academic_dataset_business.json', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            businesses.append(json.loads(line))\n",
    "    \n",
    "    return pd.DataFrame(reviews), pd.DataFrame(businesses)\n",
    "\n",
    "def search_keywords(df_reviews, keywords):\n",
    "    \"\"\"Search for specific keywords in reviews\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        matches = df_reviews[\n",
    "            df_reviews['text'].str.contains(keyword, case=False, na=False)\n",
    "        ]\n",
    "        results[keyword] = matches\n",
    "        print(f\"{keyword}: {len(matches)} mentions\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_trends(keyword_results):\n",
    "    \"\"\"Analyze yearly trends for each keyword\"\"\"\n",
    "    trends = {}\n",
    "    \n",
    "    for keyword, data in keyword_results.items():\n",
    "        data['year'] = pd.to_datetime(data['date']).dt.year\n",
    "        trend = data.groupby('year').size()\n",
    "        trends[keyword] = trend\n",
    "        print(f\"\\n{keyword} yearly trend:\")\n",
    "        print(trend)\n",
    "    \n",
    "    return trends\n",
    "\n",
    "def geographic_analysis(matches, df_business):\n",
    "    \"\"\"Analyze geographic distribution\"\"\"\n",
    "    result = matches.merge(\n",
    "        df_business[['business_id', 'name', 'city', 'state', \n",
    "                     'latitude', 'longitude', 'categories']],\n",
    "        on='business_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTop 10 cities:\")\n",
    "    print(result['city'].value_counts().head(10))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df_reviews, df_business = load_yelp_data()\n",
    "    \n",
    "    # Search for Asian flavors\n",
    "    keywords = ['black sesame', 'matcha', 'ube']\n",
    "    results = search_keywords(df_reviews, keywords)\n",
    "    \n",
    "    # Analyze trends\n",
    "    trends = analyze_trends(results)\n",
    "    \n",
    "    # Geographic analysis for black sesame\n",
    "    black_sesame_geo = geographic_analysis(results['black sesame'], df_business)\n",
    "    \n",
    "    # Save results\n",
    "    black_sesame_geo.to_csv('black_sesame_analysis.csv', index=False)\n",
    "    print(\"\\nAnalysis complete! Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65c5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 400\n",
      "Response: {'error': {'code': 'VALIDATION_ERROR', 'description': \"'Bearer your_api_key_here' does not match '^(?i)Bearer [A-Za-z0-9\\\\\\\\-\\\\\\\\_]{128}$'\", 'field': 'Authorization', 'instance': 'Bearer your_api_key_here'}}\n",
      "Error: 400\n",
      "{\"error\": {\"code\": \"VALIDATION_ERROR\", \"description\": \"'Bearer your_api_key_here' does not match '^(?i)Bearer [A-Za-z0-9\\\\\\\\-\\\\\\\\_]{128}$'\", \"field\": \"Authorization\", \"instance\": \"Bearer your_api_key_here\"}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = 'your_api_key_here'\n",
    "headers = {'Authorization': f'Bearer {API_KEY}'}\n",
    "\n",
    "params = {\n",
    "    'term': 'black sesame',\n",
    "    'location': 'San Francisco',\n",
    "    'categories': 'cafes,desserts',\n",
    "    'limit': 50\n",
    "}\n",
    "\n",
    "response = requests.get(\n",
    "    'https://api.yelp.com/v3/businesses/search',\n",
    "    headers=headers,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# 先检查响应状态和内容\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response:\", response.json())\n",
    "\n",
    "# 然后再处理数据\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if 'businesses' in data:\n",
    "        businesses = data['businesses']\n",
    "        print(f\"\\nFound {len(businesses)} businesses:\")\n",
    "        for biz in businesses:\n",
    "            print(f\"{biz['name']} - {biz['location']['city']}\")\n",
    "    else:\n",
    "        print(\"No 'businesses' key in response\")\n",
    "        print(\"Available keys:\", data.keys())\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
